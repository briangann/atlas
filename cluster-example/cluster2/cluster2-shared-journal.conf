atlas {
  environment {
    cf_port = ${?PORT}
  }

  core {
    model {
      step = 1s
    }

    db {
      class = "com.netflix.atlas.core.db.MemoryDatabase"

      // How often to rebuild the index for the memory database
      rebuild-frequency = 5s

      // 1h with 60s step
      block-size = 3600

      // 2h of data overall
      num-blocks = 2
    }
  }

  webapi {
    tags {
      max-limit = 1000000
    }

    graph {
      // Change default start time on graph to smaller range more typical for testing
      start-time = e-30m
    }

    publish {
      // Max age for a datapoint. By default it is one step interval. If the timestamps are
      // normalized locally on the client 2 times the step is likely more appropriate.s
      max-age = 21600000
      // increase default key length
      rules = [
        {
          class = "com.netflix.atlas.core.validation.KeyLengthRule"
          min-length = 2
          max-length = 128
        },
        {
          class = "com.netflix.atlas.core.validation.MaxUserTagsRule"
          limit = 100
        }
      ]
    }

  }

  akka {
    atlascluster {
      number-of-shards = 4
      cluster = [
        {
          name = "publish"
          proxy = off
          class = "com.netflix.atlas.webapi.ClusteredPublishActor"
        },
        {
          name = "db"
          proxy = off
          class = "com.netflix.atlas.webapi.ClusteredDatabaseActor"
        }
      ]
    }


    #
    # Default config will load a LocalDatabaseActor and DeadLetterStatsActor
    # clear out the list and just add in DeadLetterStatsActor (may be able to drop it too)
    actors = []
    #actors = [
    #  {
    #    name = "deadLetterStats"
    #    class = "com.netflix.atlas.akka.DeadLetterStatsActor"
    #  }
    #]

    api-endpoints = [
      "com.netflix.atlas.webapi.PublishApi",
      "com.netflix.atlas.webapi.TagsApi",
      "com.netflix.atlas.webapi.RenderApi",
      "com.netflix.atlas.webapi.GraphApi",
      "com.netflix.atlas.akka.HealthcheckApi",
      "com.netflix.atlas.akka.ConfigApi",
      "com.netflix.atlas.akka.StaticPages"
    ]
    port = 8101
  }
}

atlas.akka.name = "ClusterService"
akka.actor.debug.lifecycle = on
akka.actor.debug.receive = on
akka.actor.debug.autoreceive = on
akka.actor.debug.event-stream = on
akka.actor.debug.unhandled = on

akka {
  actor {
      provider = "akka.cluster.ClusterActorRefProvider"
      default-dispatcher {
        executor = "thread-pool-executor"

        throughput = 1
        fork-join-executor {
          parallelism-factor = 4.0
        }
      }
      deployment {
        default {
          router = "round-robin-pool"
        }
      }
      default-mailbox {
        mailbox-type = "com.netflix.atlas.akka.UnboundedMeteredMailbox"
        path-pattern = ${atlas.akka.path-pattern}
      }
      cluster-mailbox {
        mailbox-type = "com.netflix.atlas.akka.ClusterMailbox"
        path-pattern = ${atlas.akka.path-pattern}
      }
      serializers {
        kryo = "com.twitter.chill.akka.AkkaSerializer"
      }
      serialization-bindings {
        "com.netflix.atlas.core.model.Block" = kryo
        "com.netflix.atlas.core.model.CollectorStats" = kryo
        "com.netflix.atlas.core.model.ConsolidationFunction" = kryo
        "com.netflix.atlas.core.model.DataExpr" = kryo
        "com.netflix.atlas.core.model.Datapoint" = kryo
        "com.netflix.atlas.core.model.DataVocabulary" = kryo
        "com.netflix.atlas.core.model.DefaultSettings" = kryo
        "com.netflix.atlas.core.model.DsType" = kryo
        "com.netflix.atlas.core.model.EvalContext" = kryo
        "com.netflix.atlas.core.model.Expr" = kryo
        "com.netflix.atlas.core.model.FilterExpr" = kryo
        "com.netflix.atlas.core.model.FilterVocabulary" = kryo
        "com.netflix.atlas.core.model.MathExpr" = kryo
        "com.netflix.atlas.core.model.MathVocabulary" = kryo
        "com.netflix.atlas.core.model.ModelExtractors" = kryo
        "com.netflix.atlas.core.model.package" = kryo
        "com.netflix.atlas.core.model.Query" = kryo
        "com.netflix.atlas.core.model.QueryVocabulary" = kryo
        "com.netflix.atlas.core.model.ResultSet" = kryo
        "com.netflix.atlas.core.model.StatefulExpr" = kryo
        "com.netflix.atlas.core.model.StatefulVocabulary" = kryo
        "com.netflix.atlas.core.model.StyleExpr" = kryo
        "com.netflix.atlas.core.model.StyleVocabulary" = kryo
        "com.netflix.atlas.core.model.SummaryStats" = kryo
        "com.netflix.atlas.core.model.Tag" = kryo
        "com.netflix.atlas.core.model.TaggedItem" = kryo
        "com.netflix.atlas.core.model.TagKey" = kryo
        "com.netflix.atlas.core.model.TimeSeq" = kryo
        "com.netflix.atlas.core.model.TimeSeries" = kryo
        "com.netflix.atlas.core.model.TimeSeriesExpr" = kryo
        "com.netflix.atlas.core.model.FunctionTimeSeq" = kryo
        "com.netflix.atlas.core.model.ArrayTimeSeq" = kryo
        "com.netflix.atlas.core.model.OffsetTimeSeq" = kryo
        "com.netflix.atlas.core.model.MapStepTimeSeq" = kryo
        "com.netflix.atlas.core.model.BinaryOpTimeSeq" = kryo
        "com.netflix.atlas.core.model.UnaryOpTimeSeq" = kryo
        "com.netflix.atlas.core.model.ConsolidationFunction" = kryo
        "com.netflix.atlas.core.model.DsType" = kryo
        "com.netflix.atlas.core.util.SmallHashMap" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedData" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedTags" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedTagKeys" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedTagValues" = kryo
        "com.netflix.atlas.webapi.ClusteredPublishActor$IngestTaggedItem" = kryo
        "com.netflix.atlas.webapi.ClusteredPublishActor" = kryo
        "com.netflix.atlas.webapi.ClusterPublishEvt" = kryo
        "com.netflix.atlas.webapi.ClusterDatabaseEvt" = kryo
        "com.netflix.atlas.webapi.ClusterPublishState" = kryo
        "com.netflix.atlas.webapi.DatabaseProvider" = kryo
        "com.netflix.atlas.webapi.ExprApi" = kryo
        "com.netflix.atlas.webapi.GraphApi" = kryo
        "com.netflix.atlas.webapi.GraphRequestActor" = kryo
        "com.netflix.atlas.webapi.GraphApi$DataResponse" = kryo
        "com.netflix.atlas.webapi.PublishApi" = kryo
        "com.netflix.atlas.webapi.RenderApi" = kryo
        "com.netflix.atlas.webapi.TagsApi" = kryo
        "com.netflix.atlas.webapi.TagsApi$ValueListResponse" = kryo
        "com.netflix.atlas.webapi.TagsApi$KeyListResponse" = kryo
        "com.netflix.atlas.webapi.TagsApi$TagListResponse" = kryo
        "com.netflix.atlas.webapi.TagsRequestActor" = kryo
        "com.netflix.atlas.akka.ClusterMailbox" = kryo
        "akka.actor.ActorRef" = kryo
        "spray.http.HttpResponse" = kryo
      }
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2553
    }
  }

  # See http://doc.akka.io/docs/akka/snapshot/scala/cluster-sharding.html
  cluster {
    sharding {
       rebalance-interval = 10 s
       remember-entities = on
       # Setting for the default shard allocation strategy
       least-shard-allocation-strategy {
         # Threshold of how large the difference between most and least number of
         # allocated shards must be to begin the rebalancing.
         rebalance-threshold = 2

         # The number of ongoing rebalancing processes is limited to this number.
         max-simultaneous-rebalance = 1
      }
      entity-recovery-strategy = "all"
      coordinator-singleton = ${akka.cluster.singleton}

    }
    roles = [ "backend" ]
    seed-nodes = [
      "akka.tcp://ClusterService@127.0.0.1:2552"
      "akka.tcp://ClusterService@127.0.0.1:2553"
    ]

    #auto-down-unreachable-after = 10s
  }
}

cluster-mailbox {
  mailbox-type = "com.netflix.atlas.akka.ClusterMailbox"
  path-pattern = ${atlas.akka.path-pattern}
}

akka {
  persistence {
    journal {
      #plugin = "akka.persistence.journal.leveldb"
      plugin = "akka.persistence.journal.proxy"
      leveldb {
        dir = "proxyjournal"
        # Class name of the plugin.
        class = "akka.persistence.journal.leveldb.LeveldbJournal"
        # Dispatcher for the plugin actor.
        plugin-dispatcher = "akka.persistence.dispatchers.default-plugin-dispatcher"
        # Dispatcher for message replay.
        replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"
        # Storage location of LevelDB files.
        # Use fsync on write.
        fsync = on
        # Verify checksum on read.
        checksum = off
        # Native LevelDB (via JNI) or LevelDB Java port.
        native = on
      }
      proxy {
        # Class name of the plugin.
        class = "akka.persistence.journal.PersistencePluginProxy"
        # Dispatcher for the plugin actor.
        plugin-dispatcher = "akka.actor.default-dispatcher"
        # Set this to on in the configuration of the ActorSystem
        # that will host the target journal
        start-target-journal = on
        # The journal plugin config path to use for the target journal
        target-journal-plugin = "akka.persistence.journal.leveldb"
        # The address of the proxy to connect to from other nodes. Optional setting.
        target-journal-address = "akka.tcp://atlas@127.0.0.1:2552"
        # Initialization timeout of target lookup
        init-timeout = 10s
      }
    }
    snapshot-store {
      plugin = "akka.persistence.snapshot-store.proxy"
      local {
        dir = "proxysnapshot"
      }
      proxy {
        # Class name of the plugin.
        class = "akka.persistence.journal.PersistencePluginProxy"
        # Dispatcher for the plugin actor.
        plugin-dispatcher = "akka.actor.default-dispatcher"
        # Set this to on in the configuration of the ActorSystem
        # that will host the target snapshot-store
        start-target-snapshot-store = on
        # The journal plugin config path to use for the target snapshot-store
        target-snapshot-store-plugin = "akka.persistence.snapshot-store.local"
        # The address of the proxy to connect to from other nodes. Optional setting.
        target-snapshot-store-address = "akka.tcp://atlas@127.0.0.1:2552"
        # Initialization timeout of target lookup
        init-timeout = 10s
      }
    }
  }
}

# Eager initialize persistence
akka {
  extensions = [
    "akka.persistence.Persistence"
  ]
}

akka.persistence.journal.auto-start-journals = [ "akka.persistence.journal.leveldb" ]
akka.persistence.snapshot-store.auto-start-snapshot-stores = [ "akka.persistence.snapshot-store.local" ]
