atlas {
  environment {
    cf_port = ${?PORT}
  }

  core {
    model {
      step = 1s
    }

    db {
      class = "com.netflix.atlas.core.db.MemoryDatabase"

      // How often to rebuild the index for the memory database
      rebuild-frequency = 5s

      // 1h with 60s step
      block-size = 3600

      // 2h of data overall
      num-blocks = 2
    }
  }

  webapi {
    tags {
      max-limit = 1000000
    }

    graph {
      // Change default start time on graph to smaller range more typical for testing
      start-time = e-30m
    }

    publish {
      // Max age for a datapoint. By default it is one step interval. If the timestamps are
      // normalized locally on the client 2 times the step is likely more appropriate.s
      max-age = 21600000
      // increase default key length
      rules = [
        {
          class = "com.netflix.atlas.core.validation.KeyLengthRule"
          min-length = 2
          max-length = 128
        },
        {
          class = "com.netflix.atlas.core.validation.MaxUserTagsRule"
          limit = 100
        }
      ]
    }

  }

  akka {
    atlascluster {
      number-of-shards = 4
      retain-minutes = 120

      cluster = [
        {
          name = "publish"
          proxy = off
          class = "com.netflix.atlas.webapi.ClusteredPublishActor"
        },
        {
          name = "db"
          proxy = off
          class = "com.netflix.atlas.webapi.ClusteredDatabaseActor"
        }
      ]
    }


    #
    # Default config will load a LocalDatabaseActor and DeadLetterStatsActor
    # clear out the list and just add in DeadLetterStatsActor (may be able to drop it too)
    # actors = []
    actors = [
      {
        name = "deadLetterStats"
        class = "com.netflix.atlas.akka.DeadLetterStatsActor"
      }
    ]

    api-endpoints = [
      "com.netflix.atlas.webapi.PublishApi",
      "com.netflix.atlas.webapi.TagsApi",
      "com.netflix.atlas.webapi.RenderApi",
      "com.netflix.atlas.webapi.GraphApi",
      "com.netflix.atlas.akka.HealthcheckApi",
      "com.netflix.atlas.akka.ConfigApi",
      "com.netflix.atlas.akka.StaticPages"
    ]
    port = 8101
  }
}

atlas.akka.name = "ClusterService"
akka.actor.debug.lifecycle = on
akka.actor.debug.receive = on
akka.actor.debug.autoreceive = on
akka.actor.debug.event-stream = on
akka.actor.debug.unhandled = on


akka {
  actor {
      provider = "akka.cluster.ClusterActorRefProvider"
      default-dispatcher {
        executor = "thread-pool-executor"

        throughput = 1
        fork-join-executor {
          parallelism-factor = 4.0
        }
      }
      deployment {
        default {
          router = "round-robin-pool"
        }
      }
      default-mailbox {
        mailbox-type = "com.netflix.atlas.akka.UnboundedMeteredMailbox"
        path-pattern = ${atlas.akka.path-pattern}
      }
      cluster-mailbox {
        mailbox-type = "com.netflix.atlas.akka.ClusterMailbox"
        path-pattern = ${atlas.akka.path-pattern}
      }
      serializers {
        kryo = "com.twitter.chill.akka.AkkaSerializer"
      }
      serialization-bindings {
        "com.netflix.atlas.core.model.Block" = kryo
        "com.netflix.atlas.core.model.CollectorStats" = kryo
        "com.netflix.atlas.core.model.ConsolidationFunction" = kryo
        "com.netflix.atlas.core.model.DataExpr" = kryo
        "com.netflix.atlas.core.model.Datapoint" = kryo
        "com.netflix.atlas.core.model.DataVocabulary" = kryo
        "com.netflix.atlas.core.model.DefaultSettings" = kryo
        "com.netflix.atlas.core.model.DsType" = kryo
        "com.netflix.atlas.core.model.EvalContext" = kryo
        "com.netflix.atlas.core.model.Expr" = kryo
        "com.netflix.atlas.core.model.FilterExpr" = kryo
        "com.netflix.atlas.core.model.FilterVocabulary" = kryo
        "com.netflix.atlas.core.model.MathExpr" = kryo
        "com.netflix.atlas.core.model.MathVocabulary" = kryo
        "com.netflix.atlas.core.model.ModelExtractors" = kryo
        "com.netflix.atlas.core.model.package" = kryo
        "com.netflix.atlas.core.model.Query" = kryo
        "com.netflix.atlas.core.model.QueryVocabulary" = kryo
        "com.netflix.atlas.core.model.ResultSet" = kryo
        "com.netflix.atlas.core.model.StatefulExpr" = kryo
        "com.netflix.atlas.core.model.StatefulVocabulary" = kryo
        "com.netflix.atlas.core.model.StyleExpr" = kryo
        "com.netflix.atlas.core.model.StyleVocabulary" = kryo
        "com.netflix.atlas.core.model.SummaryStats" = kryo
        "com.netflix.atlas.core.model.Tag" = kryo
        "com.netflix.atlas.core.model.TaggedItem" = kryo
        "com.netflix.atlas.core.model.TagKey" = kryo
        "com.netflix.atlas.core.model.TimeSeq" = kryo
        "com.netflix.atlas.core.model.TimeSeries" = kryo
        "com.netflix.atlas.core.model.TimeSeriesExpr" = kryo
        "com.netflix.atlas.core.model.FunctionTimeSeq" = kryo
        "com.netflix.atlas.core.model.ArrayTimeSeq" = kryo
        "com.netflix.atlas.core.model.OffsetTimeSeq" = kryo
        "com.netflix.atlas.core.model.MapStepTimeSeq" = kryo
        "com.netflix.atlas.core.model.BinaryOpTimeSeq" = kryo
        "com.netflix.atlas.core.model.UnaryOpTimeSeq" = kryo
        "com.netflix.atlas.core.model.ConsolidationFunction" = kryo
        "com.netflix.atlas.core.model.DsType" = kryo
        "com.netflix.atlas.core.util.SmallHashMap" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedData" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedTags" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedTagKeys" = kryo
        "com.netflix.atlas.webapi.ClusteredDatabaseActor$GetShardedTagValues" = kryo
        "com.netflix.atlas.webapi.ClusteredPublishActor$IngestTaggedItem" = kryo
        "com.netflix.atlas.webapi.ClusteredPublishActor" = kryo
        "com.netflix.atlas.webapi.ClusterPublishEvt" = kryo
        "com.netflix.atlas.webapi.ClusterDatabaseEvt" = kryo
        "com.netflix.atlas.webapi.ClusterPublishState" = kryo
        "com.netflix.atlas.webapi.DatabaseProvider" = kryo
        "com.netflix.atlas.webapi.ExprApi" = kryo
        "com.netflix.atlas.webapi.GraphApi" = kryo
        "com.netflix.atlas.webapi.GraphRequestActor" = kryo
        "com.netflix.atlas.webapi.GraphApi$DataResponse" = kryo
        "com.netflix.atlas.webapi.PublishApi" = kryo
        "com.netflix.atlas.webapi.RenderApi" = kryo
        "com.netflix.atlas.webapi.TagsApi" = kryo
        "com.netflix.atlas.webapi.TagsApi$ValueListResponse" = kryo
        "com.netflix.atlas.webapi.TagsApi$KeyListResponse" = kryo
        "com.netflix.atlas.webapi.TagsApi$TagListResponse" = kryo
        "com.netflix.atlas.webapi.TagsRequestActor" = kryo
        "com.netflix.atlas.akka.ClusterMailbox" = kryo
        "akka.actor.ActorRef" = kryo
        "spray.http.HttpResponse" = kryo
      }
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2553
    }
  }

  # See http://doc.akka.io/docs/akka/snapshot/scala/cluster-sharding.html
  cluster {
    sharding {
       rebalance-interval = 30 s
       remember-entities = on
       # Setting for the default shard allocation strategy
       least-shard-allocation-strategy {
         # Threshold of how large the difference between most and least number of
         # allocated shards must be to begin the rebalancing.
         rebalance-threshold = 2

         # The number of ongoing rebalancing processes is limited to this number.
         max-simultaneous-rebalance = 1
      }
      entity-recovery-strategy = "all"
      coordinator-singleton = ${akka.cluster.singleton}

    }
    roles = [ "backend" ]
    seed-nodes = [
      "akka.tcp://ClusterService@127.0.0.1:2552"
      "akka.tcp://ClusterService@127.0.0.1:2553"
    ]

    #auto-down-unreachable-after = 10s
  }
}

cluster-mailbox {
  mailbox-type = "com.netflix.atlas.akka.ClusterMailbox"
  path-pattern = ${atlas.akka.path-pattern}
}

# Eager initialize persistence
akka {
  extensions = [
    "akka.persistence.Persistence"
  ]
}


# eager start journal and snapshot
#akka.persistence.journal.auto-start-journals = [ "akka-persistence-redis.journal" ]
#akka.persistence.snapshot-store.auto-start-snapshot-stores = [ "akka-persistence-redis.snapshot" ]

akka {
  persistence {
    journal {
      plugin = "akka-persistence-redis.journal"
      # eager start the journal
      auto-start-journals = [ "akka-persistence-redis.journal" ]
    }
    snapshot-store {
      plugin = "akka-persistence-redis.snapshot"
      # eager start the snapshot store
      auto-start-snapshot-stores = [ "akka-persistence-redis.snapshot" ]
    }
  }
}
akka-persistence-redis {
  journal {
    class = "com.hootsuite.akka.persistence.redis.journal.RedisJournal"
    key-namespace = "atlas-journal"
  }
  snapshot {
    class = "com.hootsuite.akka.persistence.redis.snapshot.RedisSnapshotStore"
    key-namespace = "atlas-snapshot"
  }
}

redis {
  host = "localhost"
  port = 6379
  # optional
  #password="topsecret"
}

#redis {
#  sentinel = true
#  sentinel-master = "mymaster"  //master name
#  sentinels = [{host :"localhost", port: 26379}] // list of sentinel addresses
#}
